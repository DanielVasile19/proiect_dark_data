import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score
import numpy as np
import sys

print("-------------------------------------------------")
print("ğŸš€ [Pasul 2 SIMPLU] Antrenare (TF-IDF + MLP Keras)")
print("-------------------------------------------------")

# --- 1. ÃNCÄ‚RCAREA DATELOR ---
NUME_FISIER_CSV = "rapoarte_mentenanta.csv"
try:
    df = pd.read_csv(NUME_FISIER_CSV)
    print(f"âœ… Datele sintetice '{NUME_FISIER_CSV}' au fost Ã®ncÄƒrcate. ({len(df)} rÃ¢nduri)")
except FileNotFoundError:
    print(f"EROARE: FiÈ™ierul '{NUME_FISIER_CSV}' nu a fost gÄƒsit!")
    sys.exit()

# --- 2. PREGÄ‚TIREA X È™i y ---
X = df['text_raport'].tolist()
y_text = df['eticheta_problema']

# TransformÄƒm etichetele text (ex. 'motor_defect') Ã®n numere (ex. 0)
encoder = LabelEncoder()
y = encoder.fit_transform(y_text)
num_labels = len(np.unique(y))
print(f"âœ… Datele X (text) È™i y (etichete) definite. Avem {num_labels} clase de probleme.")

# SalvÄƒm "dicÈ›ionarul" de traducere pentru mai tÃ¢rziu
# ex: [motor_defect, pompa_blocata, ...]
numele_claselor = encoder.classes_

# --- 3. ÃMPÄ‚RÈšIREA DATELOR ---
X_train_text, X_test_text, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
print(f"âœ… Datele au fost Ã®mpÄƒrÈ›ite: {len(X_train_text)} antrenare, {len(X_test_text)} testare.")

# --- 4. VECTORIZAREA (Noul mod de a transforma textul Ã®n numere) ---
print("Se creeazÄƒ 'vocabularul' TF-IDF...")
# max_features=1000 -> ne uitÄƒm doar la cele mai frecvente 1000 de cuvinte
vectorizer = TfidfVectorizer(max_features=1000)

# "ÃnvÄƒÈ›Äƒm" vocabularul DOAR pe datele de antrenare
X_train_vec = vectorizer.fit_transform(X_train_text)

# "TransformÄƒm" datele de testare folosind acelaÈ™i vocabular
X_test_vec = vectorizer.transform(X_test_text)

print(f"âœ… Datele text au fost vectorizate. Fiecare text este acum un vector cu {X_train_vec.shape[1]} numere.")

# --- 5. CONSTRUIREA MODELULUI (Keras Simplu) ---
print("Se construieÈ™te reÈ›eaua neuronalÄƒ MLP (Keras)...")

# AflÄƒm dimensiunea input-ului
dimensiune_input = X_train_vec.shape[1]  # (va fi 1000 sau mai puÈ›in)

# Keras vrea un array dens, nu matricea "sparse" de la TF-IDF
X_train_gata = X_train_vec.toarray()
X_test_gata = X_test_vec.toarray()

model = tf.keras.Sequential([
    # Stratul de intrare (Input Layer)
    tf.keras.layers.InputLayer(input_shape=(dimensiune_input,)),

    # Un strat ascuns (Hidden Layer) cu 64 de neuroni
    # 'relu' este o funcÈ›ie de activare standard
    tf.keras.layers.Dense(64, activation='relu'),

    # Un strat de Dropout (ajutÄƒ la prevenirea overfitting-ului)
    tf.keras.layers.Dropout(0.2),

    # Stratul de IeÈ™ire (Output Layer)
    # Are 'num_labels' (ex. 7) neuroni, unul pentru fiecare clasÄƒ de problemÄƒ
    # 'softmax' transformÄƒ ieÈ™irile Ã®n probabilitÄƒÈ›i (ex. 90% È™ansÄƒ 'motor_defect')
    tf.keras.layers.Dense(num_labels, activation='softmax')
])

# CompilÄƒm modelul
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',  # Perfect pentru etichetele noastre (0, 1, 2...)
    metrics=['accuracy']
)

# AfiÈ™Äƒm arhitectura
model.summary()

# --- 6. ANTRENAREA MODELULUI ---
print("\n--- Ãncepe Antrenarea ---")

history = model.fit(
    X_train_gata,
    y_train,
    epochs=10,  # Putem folosi mai multe epoci, e foarte rapid
    batch_size=16,
    validation_data=(X_test_gata, y_test),
    verbose=1
)

print("âœ… Antrenarea este finalizatÄƒ!")

# --- 7. EVALUAREA FINALÄ‚ ---
print("\n--- Evaluarea PerformanÈ›ei Finale pe Setul de Test ---")
scor_final = model.evaluate(X_test_gata, y_test, verbose=0)

print(f"Loss (Eroare): {scor_final[0]:.4f}")
print(f"Accuracy (AcurateÈ›e): {scor_final[1] * 100:.2f}%")

print("\n-------------------------------------------------")
print("ğŸ‰ FELICITÄ‚RI! Ai antrenat un model MLP pe date text!")
print("-------------------------------------------------")