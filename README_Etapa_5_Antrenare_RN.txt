# ğŸ“˜ README â€“ Etapa 5: Configurarea È™i Antrenarea Modelului RN

**Disciplina:** ReÈ›ele Neuronale  
**InstituÈ›ie:** POLITEHNICA BucureÈ™ti â€“ FIIR  
**Student:** Vasile Sorin-Daniel-Virgil  
**Link Repository GitHub:** https://github.com/DanielVasile19/proiect_dark_data  
**Data predÄƒrii:** 11.12.2025

---

## Scopul Etapei 5

AceastÄƒ etapÄƒ corespunde punctului **6. Configurarea È™i antrenarea modelului RN** din lista de 9 etape.

**Obiectiv principal:** Antrenarea efectivÄƒ a modelului RN Multi-Task definit Ã®n Etapa 4, evaluarea performanÈ›ei pe un set de test independent È™i integrarea modelului antrenat.

**Pornire obligatorie:** Arhitectura completÄƒ È™i funcÈ›ionalÄƒ din Etapa 4:
- State Machine definit È™i justificat
- Cele 3 module funcÈ›ionale (Data Logging, RN, UI)
- Minimum 40% date originale Ã®n dataset (realizat: 100% date generate sintetic)

---

## PREREQUISITE â€“ Verificare Etapa 4 (OBLIGATORIU)

**Ãnainte de a Ã®ncepe Etapa 5, s-au verificat livrabilele din Etapa 4:**

- [x] **State Machine** definit È™i documentat Ã®n `docs/state_machine.png`
- [x] **ContribuÈ›ie â‰¥40% date originale** Ã®n `data/generated/` (Dataset complet de 5000 Ã®nregistrÄƒri)
- [x] **Modul 1 (Data Logging)** funcÈ›ional - produce CSV-uri (`generare_date_v2.py`)
- [x] **Modul 2 (RN)** cu arhitecturÄƒ definitÄƒ
- [x] **Modul 3 (UI/Web Service)** funcÈ›ional
- [x] **Tabelul "Nevoie â†’ SoluÈ›ie â†’ Modul"** complet Ã®n README Etapa 4

---

## PregÄƒtire Date pentru Antrenare

Deoarece s-a extins volumul de date Ã®n Etapa 4 la 5000 de Ã®nregistrÄƒri, procesul de preprocesare a fost rulat integral pe noul dataset.

**Parametri de preprocesare utilizaÈ›i:**
- **Vectorizare:** TF-IDF (n-grams character level 3-5 chars, max features 7000).
- **Split:** 70% Train / 15% Validation / 15% Test.
- **Random State:** 42 pentru reproductibilitate.
- **Stratificare:** AplicatÄƒ pe clasa principalÄƒ pentru a asigura distribuÈ›ia echilibratÄƒ.

**Verificare dataset:**
- Total sample-uri: 5000
- Train: 3500
- Validation: 750
- Test: 750

---

## CerinÈ›e Structurate pe 3 Niveluri

### Nivel 1 â€“ Obligatoriu pentru ToÈ›i

1. **Antrenare model:** Modelul Multi-Task a fost antrenat pe setul final de 5000 date sintetice.
2. **Configurare:** Antrenarea a rulat pentru 30 epoci, cu mecanism de oprire automatÄƒ.
3. **ÃmpÄƒrÈ›ire stratificatÄƒ:** RespectatÄƒ (70/15/15).
4. **Metrici calculate pe test set:**
   - **AcurateÈ›e:** 1.0000 (100%)
   - **F1-score (macro):** 1.0000 (100%)
5. **Salvare model:** Modelul final este salvat Ã®n `models/trained_model.h5`.
6. **Integrare UI:** InterfaÈ›a Ã®ncarcÄƒ acum modelul antrenat È™i realizeazÄƒ inferenÈ›e reale (demonstrat Ã®n screenshot).

#### Tabel Hiperparametri È™i JustificÄƒri

| **Hiperparametru** | **Valoare AleasÄƒ** | **Justificare** |
|--------------------|-------------------|-----------------|
| **Learning rate** | 0.001 | Valoare standard pentru optimizatorul Adam, asigurÃ¢nd o convergenÈ›Äƒ rapidÄƒ È™i stabilÄƒ pe date sparse (TF-IDF). |
| **Batch size** | 32 | Echilibru optim Ã®ntre utilizarea memoriei È™i stabilitatea gradientului pentru un dataset de 5000 samples. |
| **Number of epochs** | 30 | NumÄƒr suficient pentru a atinge convergenÈ›a, controlat de Early Stopping pentru a preveni overfitting-ul. |
| **Optimizer** | Adam | EficienÈ›Äƒ superioarÄƒ pentru probleme NLP cu vectori rari, datoritÄƒ ajustÄƒrii automate a ratei de Ã®nvÄƒÈ›are per parametru. |
| **Loss function** | Sparse Categorical Crossentropy | AdecvatÄƒ pentru clasificare multi-class cu etichete integer (nebinarizate) pe 3 ieÈ™iri distincte. |
| **Activation functions** | ReLU (hidden), Softmax (output) | ReLU previne vanishing gradient Ã®n straturile dense; Softmax este necesar pentru distribuÈ›ia probabilisticÄƒ pe clasele de ieÈ™ire. |

---

### Nivel 2 â€“ Recomandat

S-au implementat urmÄƒtoarele optimizÄƒri:

1. **Early Stopping:** Monitorizarea metricii `val_loss` cu `patience=5`. Antrenarea s-a oprit automat È™i a restaurat cei mai buni ponderi (`restore_best_weights=True`).
2. **AugmentÄƒri relevante:** Generarea datelor sintetice a inclus variaÈ›ii de topicÄƒ (inversiuni subiect-predicat) È™i introducerea de greÈ™elilor de scriere pentru a robustiza modelul la input uman imperfect.
3. **Grafic loss È™i val_loss:** Salvat Ã®n `docs/loss_curve.png`. Curbele indicÄƒ o convergenÈ›Äƒ rapidÄƒ È™i stabilÄƒ, fÄƒrÄƒ divergenÈ›e majore Ã®ntre antrenare È™i validare.

**Indicatori obÈ›inuÈ›i:**
- **AcurateÈ›e:** 100% (Target Nivel 2: â‰¥ 75%)
- **F1-score:** 1.00 (Target Nivel 2: â‰¥ 0.70)

---

## Verificare ConsistenÈ›Äƒ cu State Machine (Etapa 4)

Antrenarea È™i inferenÈ›a respectÄƒ fluxul definit Ã®n State Machine:

| **Stare din Etapa 4** | **Implementare Ã®n Etapa 5** |
|-----------------------|-----------------------------|
| `ACQUIRE_DATA` | Generatorul `generare_date_v2.py` produce datele brute pentru antrenare. |
| `PREPROCESS` | Vectorizatorul TF-IDF antrenat (`vectorizer_v2.joblib`) este aplicat pe input-ul utilizatorului Ã®n UI. |
| `RN_INFERENCE` | Se apeleazÄƒ `model.predict()` folosind `trained_model.h5` (modelul real, nu dummy). |
| `DISPLAY` | Rezultatele (ProblemÄƒ, Departament, UrgenÈ›Äƒ) sunt afiÈ™ate Ã®n Dashboard cu scoruri de Ã®ncredere reale. |
| `FEEDBACK_LOOP` | CorecÈ›iile manuale sunt salvate Ã®n dataset pentru cicluri viitoare de antrenare. |

AnalizÄƒ Erori Ã®n Context Industrial (Nivel 2)
DeÈ™i pe setul de test sintetic performanÈ›a este maximÄƒ (datoritÄƒ consistenÈ›ei regulilor de generare), Ã®ntr-un mediu industrial real anticipÄƒm urmÄƒtoarele provocÄƒri:

1. Pe ce clase greÈ™eÈ™te cel mai mult modelul?
PotenÈ›iale confuzii Ã®ntre "Eroare Software" È™i "Eroare HMI". CauzÄƒ: Suprapunere semanticÄƒ mare (ambele implicÄƒ ecrane/interfeÈ›e). Operatorii pot descrie o eroare de interfaÈ›Äƒ (HMI) ca fiind o "eroare de soft".

2. Ce caracteristici ale datelor cauzeazÄƒ erori?
Textele extrem de scurte (ex: "defect", "nu merge") sau ambigue. Exemplu: "Linia s-a oprit". Poate fi o cauzÄƒ mecanicÄƒ, electricÄƒ sau de siguranÈ›Äƒ. FÄƒrÄƒ context suplimentar, TF-IDF nu poate extrage trÄƒsÄƒturi suplimentare.

3. Ce implicaÈ›ii are pentru aplicaÈ›ia industrialÄƒ?
False Positives (AlarmÄƒ falsÄƒ): Acceptabil.

Misclassification (Departament greÈ™it): Critic. Trimiterea unui electrician la o problemÄƒ mecanicÄƒ (ex: scurgere ulei) duce la creÈ™terea timpului de staÈ›ionare (downtime).

Prioritate: Maximizarea preciziei pe clasa "Departament" pentru a asigura rutarea corectÄƒ a personalului.

4. Ce mÄƒsuri corective propuneÈ›i?
Human-in-the-Loop: MenÈ›inerea funcÈ›ionalitÄƒÈ›ii de feedback din UI pentru a colecta date reale È™i a re-antrena modelul periodic.

Extinderea Vocabularului: AdÄƒugarea continuÄƒ de termeni de argou specifici fabricii Ã®n setul de antrenare.

Prag de SiguranÈ›Äƒ: Implementarea unui confidence threshold. DacÄƒ Ã®ncrederea predicÈ›iei este < 70%, sistemul sÄƒ solicite operatorului sÄƒ selecteze manual departamentul.
Structura arhitecturii proiectului:
proiect_dark_data/
â”œâ”€â”€ README.md                        
â”œâ”€â”€ README_Etapa4_Arhitectura_SIA.txt 
â”œâ”€â”€ README_Etapa5_Antrenare_RN.md    
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ state_machine.png            
â”‚   â”œâ”€â”€ loss_curve.png               # Graficul curbelor de antrenare 
â”‚   â””â”€â”€ screenshots/
â”‚       â”œâ”€â”€ ui_demo.png              # UI Demo 
â”‚       â””â”€â”€ inference_real.png       
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                        
â”‚   â”œâ”€â”€ generated/                   
â”‚   â”œâ”€â”€ processed/                   
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_acquisition/            
â”‚   â”œâ”€â”€ neural_network/
â”‚   â”‚   â”œâ”€â”€ train_model.py           
â”‚   â”‚   â””â”€â”€ predict_dispecer.py      
â”‚   â””â”€â”€ app/
â”‚       â””â”€â”€ dashboard.py             # UI Streamlit
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ trained_model.h5             # Modelul antrenat
â”‚   â””â”€â”€ *.joblib                     # Encoderele È™i vectorizatorul
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ training_history.csv         
â”‚   â””â”€â”€ test_metrics.json            # Rezultate finale
â”‚
â”œâ”€â”€ config/
â””â”€â”€ requirements.txt